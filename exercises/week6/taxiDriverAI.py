# En agent som ska l√§ra sig plocka upp och l√§mna av passagerare p√• r√§tt platser
# Anv√§nder en f√∂renklad version av Gymnasiums Taxi-milj√∂

import gymnasium as gym
import numpy as np
from collections import defaultdict
import time

class SimpleTaxi(gym.Env):
    """
    Enkel taxiv√§rld d√§r en taxi ska plocka upp en passagerare och l√§mna av den.
    V√§rlden √§r ett 5x5 rutn√§t med fyra m√∂jliga upph√§mtningsplatser (R, G, B, Y).
    """
    def __init__(self):
        # V√§rlden √§r 5x5, taxi kan vara p√• vilken ruta som helst
        # F√∂r varje ruta kan passageraren vara p√• 4 olika platser eller i taxin
        # Passageraren ska till n√•gon av de 4 platserna
        self.observation_space = gym.spaces.Discrete(5 * 5 * 5 * 4)
        
        # M√∂jliga handlingar: upp, h√∂ger, ner, v√§nster, plocka upp, l√§mna av
        self.action_space = gym.spaces.Discrete(6)
        
        # Platsernas positioner (rad, kolumn)
        self.locations = {
            'R': (0, 0),  # R√∂d plats
            'G': (0, 4),  # Gr√∂n plats
            'B': (4, 0),  # Bl√• plats
            'Y': (4, 4)   # Gul plats
        }
        
        self.reset()
    
    def encode_state(self):
        """Konverterar nuvarande tillst√•nd till ett unikt nummer"""
        # taxi_row * 100 + taxi_col * 20 + passenger_loc * 4 + destination
        return (self.taxi_row * 100 + 
                self.taxi_col * 20 + 
                self.passenger_location * 4 + 
                self.destination)
    
    def decode_state(self, state):
        """Avkodar ett tillst√•ndsnummer till dess komponenter"""
        taxi_row = state // 100
        state = state % 100
        taxi_col = state // 20
        state = state % 20
        passenger_loc = state // 4
        destination = state % 4
        return taxi_row, taxi_col, passenger_loc, destination
    
    def reset(self, seed=None):
        super().reset(seed=seed)
        
        # Placera taxi slumpm√§ssigt
        self.taxi_row = self.np_random.integers(5)
        self.taxi_col = self.np_random.integers(5)
        
        # V√§lj slumpm√§ssig start och destination (0-3 motsvarar R,G,B,Y)
        self.passenger_location = self.np_random.integers(4)  # Passagerarens startplats
        self.destination = self.np_random.integers(4)        # Destinationen
        while self.destination == self.passenger_location:   # Se till att de √§r olika
            self.destination = self.np_random.integers(4)
        
        return self.encode_state(), {}
    
    def step(self, action):
        """
        Utf√∂r en handling och returnerar nytt tillst√•nd, bel√∂ning, om klart, etc.
        F√∂rb√§ttrad bel√∂ningsstruktur f√∂r att undvika loopar
        """
        prev_row, prev_col = self.taxi_row, self.taxi_col
        reward = -1  # Standardbel√∂ning f√∂r varje steg
        done = False
        
        if action < 4:  # F√∂rflyttningshandlingar
            if action == 0:  # Upp
                self.taxi_row = max(0, self.taxi_row - 1)
            elif action == 1:  # H√∂ger
                self.taxi_col = min(4, self.taxi_col + 1)
            elif action == 2:  # Ner
                self.taxi_row = min(4, self.taxi_row + 1)
            elif action == 3:  # V√§nster
                self.taxi_col = max(0, self.taxi_col - 1)
            
            # Extra bestraffning om taxin inte r√∂rde sig (k√∂rde in i v√§gg)
            if (self.taxi_row, self.taxi_col) == (prev_row, prev_col):
                reward = -2
                
            # Mindre bestraffning n√§r taxin r√∂r sig mot m√•let
            if self.passenger_location < 4:  # Om passageraren v√§ntar
                target = list(self.locations.values())[self.passenger_location]
            else:  # Om passageraren √§r i taxin
                target = list(self.locations.values())[self.destination]
                
            # Ber√§kna om vi kom n√§rmare m√•let
            prev_dist = abs(prev_row - target[0]) + abs(prev_col - target[1])
            new_dist = abs(self.taxi_row - target[0]) + abs(self.taxi_col - target[1])
            if new_dist < prev_dist:
                reward = -0.5  # Mindre bestraffning f√∂r att r√∂ra sig mot m√•let
            
        elif action == 4:  # Plocka upp
            if self.passenger_location < 4:  # Om passageraren inte redan √§r i taxin
                loc_coords = list(self.locations.values())[self.passenger_location]
                if (self.taxi_row, self.taxi_col) == loc_coords:
                    self.passenger_location = 4  # 4 betyder "i taxin"
                    reward = 15  # √ñka bel√∂ningen f√∂r upph√§mtning
                else:
                    reward = -10
            else:
                reward = -10
                
        elif action == 5:  # L√§mna av
            dest_coords = list(self.locations.values())[self.destination]
            if (self.taxi_row, self.taxi_col) == dest_coords and self.passenger_location == 4:
                self.passenger_location = self.destination
                reward = 30  # √ñka bel√∂ningen f√∂r korrekt avl√§mning
                done = True
            else:
                reward = -10
                
        return self.encode_state(), reward, done, False, {}
    
def visualize_taxi(env):
    """
    Skapar en textbaserad visualisering av taxi-milj√∂n
    """
    # Skapa en representation av v√§rlden
    world = [['‚ñë' for _ in range(5)] for _ in range(5)]
    
    # Markera platserna
    locations = {
        0: 'R',  # R√∂d plats
        1: 'G',  # Gr√∂n plats
        2: 'B',  # Bl√• plats
        3: 'Y'   # Gul plats
    }
    
    # Placera ut platsmark√∂rer
    world[0][0] = 'R'
    world[0][4] = 'G'
    world[4][0] = 'B'
    world[4][4] = 'Y'
    
    # Placera taxi
    world[env.taxi_row][env.taxi_col] = 'üöï' if env.passenger_location == 4 else 'üöñ'
    
    # Markera passagerarens position om den inte √§r i taxin
    if env.passenger_location < 4:
        pos = list(env.locations.values())[env.passenger_location]
        world[pos[0]][pos[1]] = f'P{locations[env.passenger_location]}'
    
    # Markera destinationen
    dest = list(env.locations.values())[env.destination]
    world[dest[0]][dest[1]] = f'D{locations[env.destination]}'
    
    # Skriv ut v√§rlden
    print("\033[H\033[J")  # Rensa terminalf√∂nstret
    print("Taxi World - üöñ=tom taxi, üöï=taxi med passagerare")
    print("P=Passagerare, D=Destination")
    for row in world:
        print(' '.join(row))
    print("\n")

def train_taxi_driver(episodes=2000, render=False):  # √ñka antal episoder
    """
    Tr√§nar en Q-learning agent f√∂r taxi-milj√∂n med f√∂rb√§ttrade parametrar
    """
    env = SimpleTaxi()
    
    # Initialisera Q-tabell med sm√• slumpm√§ssiga v√§rden ist√§llet f√∂r nollor
    q_table = defaultdict(lambda: np.random.uniform(low=-1, high=1, size=6))
    
    # Justerade hyperparametrar
    learning_rate = 0.15
    discount_factor = 0.99  # √ñka f√∂r att v√§rdera framtida bel√∂ningar h√∂gre
    epsilon = 1.0
    epsilon_decay = 0.998  # L√•ngsammare decay
    epsilon_min = 0.05  # H√∂gre minimum f√∂r att beh√•lla viss exploration
    
    # F√∂r att sp√•ra prestanda
    rewards_history = []
    steps_history = []
    
    for episode in range(episodes):
        state, _ = env.reset()
        total_reward = 0
        steps = 0
        
        while True:
            if render and episode % 100 == 0:
                visualize_taxi(env)
                time.sleep(0.1)
            
            # Epsilon-greedy med lite modifiering f√∂r att uppmuntra m√•lmedvetet beteende
            if np.random.random() < epsilon:
                action = env.action_space.sample()
            else:
                # Om det finns flera handlingar med samma v√§rde, v√§lj slumpm√§ssigt bland dem
                best_value = np.max(q_table[state])
                best_actions = np.where(q_table[state] == best_value)[0]
                action = np.random.choice(best_actions)
            
            next_state, reward, done, _, _ = env.step(action)
            total_reward += reward
            steps += 1
            
            # Q-learning uppdatering med lite h√∂gre learning rate f√∂r positiva bel√∂ningar
            old_value = q_table[state][action]
            next_max = np.max(q_table[next_state])
            
            # Anv√§nd h√∂gre learning rate f√∂r positiva bel√∂ningar
            current_lr = learning_rate * 1.5 if reward > 0 else learning_rate
            
            new_value = (1 - current_lr) * old_value + current_lr * (reward + discount_factor * next_max)
            q_table[state][action] = new_value
            
            state = next_state
            
            if done or steps > 100:  # Avbryt om klar eller f√∂r m√•nga steg
                break
        
        # Uppdatera epsilon med decay
        epsilon = max(epsilon_min, epsilon * epsilon_decay)
        
        # Spara historik
        rewards_history.append(total_reward)
        steps_history.append(steps)
        
        # Visa framsteg var 100:e episode
        if (episode + 1) % 100 == 0:
            avg_reward = np.mean(rewards_history[-100:])
            avg_steps = np.mean(steps_history[-100:])
            print(f"Episode {episode + 1}")
            print(f"Genomsnittlig bel√∂ning: {avg_reward:.2f}")
            print(f"Genomsnittliga steg: {avg_steps:.2f}")
            print(f"Epsilon: {epsilon:.2f}")
            print("-" * 40)
    
    return q_table

def run_trained_taxi(q_table, episodes=5):
    """
    K√∂r den tr√§nade taxin n√•gra episoder f√∂r demonstration
    """
    env = SimpleTaxi()
    
    for episode in range(episodes):
        state, _ = env.reset()
        total_reward = 0
        steps = 0
        print(f"\nEpisod {episode + 1}")
        
        while True:
            visualize_taxi(env)
            time.sleep(0.5)  # Paus f√∂r att kunna se vad som h√§nder
            
            # V√§lj b√§sta handling enligt Q-tabellen
            action = np.argmax(q_table[state])
            
            # Utf√∂r handling
            state, reward, done, _, _ = env.step(action)
            total_reward += reward
            steps += 1
            
            if done or steps > 100:
                visualize_taxi(env)
                print(f"Episod klar! Total bel√∂ning: {total_reward}, Antal steg: {steps}")
                time.sleep(2)
                break

# F√∂r att k√∂ra tr√§ningen och demonstrationen:
if __name__ == "__main__":
    print("Tr√§nar taxichauff√∂ren...")
    q_table = train_taxi_driver(episodes=1000, render=True)
    print("\nTr√§ning klar! K√∂r n√•gra demonstrationsepisoder...")
    run_trained_taxi(q_table)
    
# F√∂r att k√∂ra tr√§ningen:
if __name__ == "__main__":
    print("Tr√§nar taxichauff√∂r...")
    q_table = train_taxi_driver()
    print("Tr√§ning klar!")